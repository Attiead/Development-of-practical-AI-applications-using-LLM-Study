## 8 sLLM 서빙하기
- AI에서 **서빙(Serving)**이란, 모델을 클라이언트(사용자)가 사용할 수 있도록 배포하고 제공(Serving)하는 과정
- 효율적인 추론 전략이 필요한 이유:
  - LLM은 엄청난 파라미터 수(수십억~수천억 개)를 가진 대형 모델이야. 이런 모델을 추론 단계에서 효율적으로 사용하려면 다음과 같은 문제가 있어:
    - 메모리(RAM, VRAM) 한계
    - 처리 속도(지연 시간)
    - 비용(GPU 시간, 클라우드 비용)
    - 전력 소모
  - 그래서 **"효율적인 추론 전략"**이 필요
    - 사용자가 답변을 받기까지 시간이 오래 걸리고,
    - GPU 자원은 낭비되고,
    - 서비스 비용은 폭등해.
### 8.3 효율적인 추론 전략
#### 8.3.1 커널 퓨전
- 
